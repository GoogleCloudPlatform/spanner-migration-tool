***WARNING: HarbourBridge is currently under development, and not all modules
have been merged yet. In short, it probably won't compile right now. Please
check back later.  Or take a look at [pending pull
requests](https://github.com/cloudspannerecosystem/harbourbridge/pulls).***

# HarbourBridge: Turnkey Postgres-to-Spanner Evaluation

HarbourBridge is a stand-alone open-source tool for Cloud Spanner evaluation,
using data from an existing PostgreSQL database. The tool ingests pg_dump
output, automatically builds a Spanner schema, and creates a new Spanner
database populated with data from pg_dump. The tool is designed to simplify
Spanner evaluation. It is not intended for production database migration. In
particular, statements and features in the pg_dump output that don't map
directly on Spanner features are simply ignored. It is also not intended for
databases larger than a couple of GB.

To use the tool on a PostgreSQL database called mydb, run

```sh
pg_dump mydb | harbourbridge
```

HarbourBridge accepts pg_dump's standard plain-text format, but not archive or
custom formats.

HarbourBridge automatically determines the cloud project and Spanner instance to
use, and generates a new Spanner database name (prefixed with `pg_dump_` and
today's date). Command-line flags can be used to explicitly set the Spanner
instance or database name.

**WARNING: Please check that permissions for the Spanner instance used by
HarbourBridge are appropriate. Spanner manages access control at the database
level, and the database created by HarbourBridge will inherit default
permissions from the instance. All data written by HarbourBridge is visible to
anyone who can access the created database.**

As it processes the pg_dump data, HarbourBridge reports on progress, provides
stats on the schema and data conversion steps, and an overall assessment of the
quality of the conversion. It also generates a schema file and report file (and
a bad-data file if data was dropped). See
[Files Generated by HarbourBridge](#files-generated-by-harbourbridge). Details
of how PostgreSQL is mapped to Spanner can be found in the
[Schema Conversion](#schema-conversion) section.

This tool is part of the Cloud Spanner Ecosystem, a community contributed and
supported open-source repository. Please [report
issues](https://github.com/cloudspannerecosystem/harbourbridge/issues) and send
pull requests. Note that this tool is not officially supported as part of the
Cloud Spanner product.

## Quickstart Guide

### Before you begin

Complete the steps described in
[Set up](https://cloud.google.com/spanner/docs/getting-started/set-up), which
covers creating and setting a default Google Cloud project, enabling billing,
enabling the Cloud Spanner API, and setting up OAuth 2.0 to get authentication
credentials to use the Cloud Spanner API.

In particular, ensure that you run

```sh
gcloud auth application-default login
```

to set up your local development environment with authentication credentials.

Set the GCLOUD_PROJECT environment variable to your Google Cloud project ID:

```sh
export GCLOUD_PROJECT=[MY_PROJECT_ID]
```

If you do not already have a Cloud Spanner instance, or you want to use a
separate instance specifically for running HarbourBridge, then create a Cloud
Spanner instance by following the "Create an instance" instructions on the
[Quickstart using the console](https://cloud.google.com/spanner/docs/quickstart-console)
guide. HarbourBridge will create a database for you, but it will not create a
Spanner instance.

Install Go ([download](https://golang.org/doc/install)) on your development
machine if it is not already installed, configure the GOPATH environment
variable if it is not already configured, and
[test your installation](https://golang.org/doc/install#testing).

### Installing HarbourBridge

Download the tool to your machine and install it.

```sh
go get -u github.com/cloudspannerecosystem/harbourbridge
```

The tool should now be installed as `$GOPATH/bin/harbourbridge`

### Running HarbourBridge

To use the tool on a PostgreSQL database called mydb, run

```sh
pg_dump mydb | $GOPATH/bin/harbourbridge
```

This command will use the cloud project specified by the GCLOUD_PROJECT
environment variable, automatically determine the Cloud Spanner instance
associated with this project, convert the PostgreSQL schema for `mydb` to a
Spanner schema, create a new Cloud Spanner database with this schema, and
finally, populate this new database with the data from `mydb`. The new Cloud
Spanner database will have a name of the form `pg_dump_{DATE}_{RANDOM}`, where
`{DATE}` is today's date, and `{RANDOM}` is a random suffix for uniqueness.

See the [Troubleshooting Guide](#troubleshooting-guide) for help on debugging
issues.

## Files Generated by HarbourBridge

HarbourBridge generates several files as it runs:

-   Schema file (ending in `.schema.txt`): contains the generated Spanner
    schema, interspersed with comments that cross-reference to the relevant
    PostgreSQL schema definitions.

-   Report file (ending in `.report.txt`) contains a detailed analysis of the
    PostgreSQL to Spanner migration, including table-by-table stats and an
    analysis of PostgreSQL types that don't cleanly map onto Spanner types. Note
    that PostgreSQL types that don't have a corresponding Spanner type are
    mapped to STRING(MAX).

-   Bad data file (ending in `.dropped.txt`): contains details of pg_dump data
    that could not be converted and written to Spanner, including sample
    bad-data rows. If there is no bad-data, this file is not written (and we
    delete any existing file with the same name from a previous run).
    
The prefix for these file is defined by the value of the `-prefix` option, and
defaults to the name of the Spanner database. See [Options](#options) for
details.

## Options

HarbourBridge accepts the following options:

`-dbname` Specifies the name of the Spanner database to create. This must be a
new database. If dbname is not specified, HarbourBridge creates a new unique
dbname.

`-instance` Specifies the Spanner instance to use. The new database will be
created in this instance. If not specified, the tool automatically determines an
appropriate instance using gcloud.

`-prefix` Specifies a file prefix for the report, schema and bad-data files
written by the tool. If no file prefix is specified, the name of the Spanner
database is used.

`-v` Specifies verbose mode. This will cause HarbourBridge to output detailed
messages about the conversion.

## Example Usage

The following examples assume ``harbourbridge`` has been added to your PATH
environment variable.

To use HarbourBridge on a PostgreSQL database called mydb, run:

```sh
pg_dump mydb | harbourbridge
```

The tool can also be applied to an existing pg_dump file:

```sh
harbourbridge < my_pg_dump_file
```

To specify a particular Spanner instance to use, run:

```sh
pg_dump mydb | harbourbridge -instance my-spanner-instance
```

By default, HarbourBridge will generate a new Spanner database name to populate.
You can override this and specify the database name to use by:

```sh
pg_dump mydb | harbourbridge -dbname my-spanner-database-name
```

HarbourBridge generates a report file, a schema file and a bad-data file (if
there are bad-data rows). You can control where these files are written by
specifying a file prefix. For example,

```sh
pg_dump mydb | harbourbridge -prefix mydb.
```

will write files `mydb.report.txt`, `mydb.schema.txt` and
`mydb.dropped.txt`. The prefix can also be a directory. For example,


```sh
pg_dump mydb | harbourbridge -prefix ~/spanner-eval-mydb/
```

would write the files into the directory `~/spanner-eval-mydb/`. Note
that HarbourBridge will not create directories as it writes these files.

## Schema Conversion

The HarbourBridge tool maps PostgreSQL types to Spanner types as follows:

| PostgreSQL Type    | Spanner Type           | Notes                         |
| ------------------ | ---------------------- | ----------------------------- |
| `BOOL`             | `BOOL`                 |                               |
| `BIGINT`           | `INT64`                |                               |
| `BIGSERIAL`        | `INT64`                | a                             |
| `BYTEA`            | `BYTES(MAX)`           |                               |
| `CHAR`             | `STRING(MAX)`          |                               |
| `CHAR(N)`          | `STRING(N)`            |                               |
| `DATE`             | `DATE`                 |                               |
| `DOUBLE PRECISION` | `FLOAT64`              |                               |
| `INTEGER`          | `INT64`                | s                             |
| `NUMERIC`          | `FLOAT64`              | p                             |
| `REAL`             | `FLOAT64`              | s                             |
| `SERIAL`           | `INT64`                | a, s                          |
| `SMALLINT`         | `INT64`                | s                             |
| `TEXT`             | `STRING(MAX)`          |                               |
| `TIMESTAMP`        | `TIMESTAMP`            | t                             |
| `TIMESTAMPTZ`      | `TIMESTAMP`            |                               |
| `VARCHAR`          | `STRING(MAX)`          |                               |
| `VARCHAR(N)`       | `STRING(N)`            |                               |
| `ARRAY(`pgtype`)`  | `ARRAY(`spannertype`)` | if scalar type pgtype maps to spannertype |

All other types map to `STRING(MAX)`. Some of the mappings in this table
represent loss of precision (marked p), dropped autoincrement functionality
(marked a), differences in treatment of timezones (marked t) and changes in
storage size (marked s). We discuss each in turn, as well as other limits and
notes on schema conversion.

### `NUMERIC`

Spanner does not support numeric types, so these are mapped to `FLOAT64`. For
some numeric types (e.g. `NUMERIC(7, 3))` this mapping will preserve precision.
But for others, the numeric type does not fit in `FLOAT64`; HarbourBridge
generates a warning in such cases. In general, mapping `NUMERIC` to `FLOAT64`
can be useful for evaluation purposes, but it is not recommended for production
use.

### `BIGSERIAL` and `SERIAL`

Spanner does not support autoincrementing types, so these both map to `INT64`
and the autoincrementing functionality is dropped.

### `TIMESTAMP`

PosgreSQL has two timestamp types: `TIMESTAMP` and `TIMESTAMPTZ`. Both have an 8
byte data representation and provide microsecond resolultion, but neither
actually stores a timezone with the data. The keys difference between the two
types is how string literals are converted to timestamps and queries return
data. For `TIMESTAMP`, all timezone information is dropped, and data is returned
without a timezone. For `TIMESTAMPTZ`, string literals are converted to UTC,
using the literal's timezone if it is specified, or the PostgreSQL's timezone
paramater if not. When data is printed stored data (in UTC) is converted to the
timezone from the timezone parameter

Spanner has a single timestamp type. Data is stored as UTC (there is no separate
timezone) Spanner client libraries convert timestamps to UTC before sending them
to Spanner. Data is always returned as UTC. Spanner's timestamp type is
essentially the same as `TIMESTAMPTZ`, except that there is no analog of
PostgreSQL's timezone parameter.

In other words, mapping PostgreSQL `TIMESTAMPTZ` to `TIMESTAMP` is fairly
straightforward, but care should be taken with PostgreSQL `TIMESTAMP` data
because Spanner clients will not drop the timezone.

### Storage Use

The tool maps several PostgreSQL types to Spanner types that use more storage.
For example, `SMALLINT` is a two-byte integer, but it maps to Spanner's
`INT64`, an eight-byte integer. This additional storage could be significant for
large arrays.

### Arrays

Spanner does not support multi-dimensional arrays. So while `TEXT[4]` maps to
`ARRAY<STRING(MAX)>` and `REAL ARRAY` maps to `ARRAY<FLOAT64>`, `TEXT[][]` maps
to `STRING(MAX)`.

Also note that PosgreSQL supports array limits, but the PostgreSQL
implementation ignores them. Spanner does not support array size limits, but
since they have no effect anyway, the tool just drops them.

### Primary Keys

Spanner requires primary keys for all tables. PostgreSQL recommends the use of
primary keys for all tables, but does not enforce this. When converting a table
without a primary key, HarbourBridge will create a new primary key of type
INT64. By default, the name of the new column is `synth_id`. If there is already
a column with that name, then a variation is used to avoid collisions.

### NOT NULL Constraints

The tool preserves `NOT NULL` constraints. Note that Spanner does not require
primary key columns to be `NOT NULL`. However, in PostgreSQL, a primary key is a
combination of `NOT NULL` and `UNIQUE`, and so primary key columns from
PostgreSQL will be mapped to Spanner columns that are both primary keys and `NOT
NULL`.

### Foreign Keys and Default Values

Spanner does not currently support foreign keys or default values. We drop these
PostgreSQL features during conversion.

### Other PostgreSQL features

PostgreSQL has many other features we haven't discussed, including functions,
sequences, procecdures, triggers, (non-primary) indexes and views. The tool does
not support these and the relevant statements are dropped during schema
conversion.

See
[Migrating from PostgreSQL to Cloud Spanner](https://cloud.google.com/spanner/docs/migrating-postgres-spanner)
for a general discussion of PostgreSQL to Spanner migration issues.
HarbourBridge follows most of the recommendations in that guide. The main
difference is that we map a few more types to `STRING(MAX)`.

## Data Conversion

HarbourBridge converts PostgreSQL data to Spanner data based on the Spanner
schema it constructs. Conversion for most data types is fairly straightforward,
but several types deserve discussion. Note that HarbourBridge is not intended
for databases larger than a couple of GB.

### Timestamps and Timezones

As noted earlier when discussing [schema conversion of
TIMESTAMP](#timestamp), there are some sutble differences in how timestamps are
handled in PostgreSQL and Spanner.

During data conversion, PostgreSQL `TIMESTAMPTZ` values are converted to UTC and
stored in Spanner. The conversion proceeds as follows. If the value has a
timezone, that timezone is respected during the conversion to UTC. If the value
does not have a timezone, then we look for any `set timezone` statements in the
pg_dump output and use the timezone specified. Otherwise, we use the `TZ`
environment variable as the timezone, and failing that, we use the local system
timezone default (as determined by go).

In constrast, conversion of PostgreSQL `TIMESTAMP` values proceeds by ignoring
any timezone information and just treating the value as UTC and storing it in
Spanner.

### Strings, character set support and UTF-8

Spanner requires that `STRING` values be UTF-8 encoded. All Spanner functions
and operators that act on `STRING` values operate on Unicode characters rather
than bytes. Since we map many PostgreSQL types (including `TEXT` and `CHAR`
types) to Spanner's `STRING` type, HarbourBridge is effectively a UTF-8 based
tool.

Note that the tool itself does not do any encoding/decoding or UTF-8 checks: it
passes through data from pg_dump to Spanner. Internally, we use go's string
type, which supports UTF-8.

## Troubleshooting Guide

The following steps can help diagnose common issues encountered while running
HarbourBridge.

### 1. Verify pg_dump configuration

First, check that pg_dump is correctly configured to connect to your PostgreSQL
database. Note that pg_dump uses the same options as psql to connect to your
database. See the [psql](https://www.postgresql.org/docs/9.3/app-psql.html) and
[pg_dump](https://www.postgresql.org/docs/9.3/app-pgdump.html) documentation.

Access to a PostgreSQL database is typically configured using the following
environment variables, which are standard across PostgreSQL utilities including
pg_dump:

```sh
PGHOST
PGPORT
PGUSER
```

It is also possible to configure access via the command-line options `--host`,
`--port` and `--username`.

### 2. Verify pg_dump output

Next, verify that pg_dump is generating plain-text output. If your database is
small, try running

```sh
pg_dump > file
```

and look at the output file. It should be a plain-text file containing SQL
commands. If your database is large, consider just dumping the schema via the
`--schema-only` pg_dump command-line option.

pg_dump can export data in a variety of formats, but HarbourBridge only accepts
`plain` format (aka plain-text). See the
[pg_dump documentation](https://www.postgresql.org/docs/9.3/app-pgdump.html) for
details about formats.

### 3. Debugging HarbourBridge

The HarbourBridge tool can fail for a number of reasons

-   Unparsable pg_dump: HarbourBridge uses the
    [pg_query_go](https://github.com/lfittl/pg_query_go) library. It is possible
    that the pg_dump output is corrupted or uses features that aren't parseable.
    Parsing errors should generate an error message of the form `Error parsing
    last 54321 line(s) of input`.

-   Credentials problems: HarbourBridge uses standard Google Cloud credential
    mechanisms for accessing Cloud Spanner. If this is mis-configured, you may
    see errors containing "unauthenticated", or "cannot fetch token", or "could
    not find default credentials". You might need to run `gcloud auth
    application-default login`. See the [Before you begin](#before-you-being)
    section for details.

-   Can't create database: the error message printed by the tool should help
    identify the cause. It could be an API permissions issue. For example, the
    Cloud Spanner API may not be appropriately configured. See
    [Before you begin](#before-you-being) section for details. Alternatively,
    you have have hit the limit on the number of databases per instances
    (currently 100). This can occur if you re-run the HarbourBridge tool many
    times, since each run creates a new database. In this case you'll need to
    [delete some databases](https://cloud.google.com/spanner/docs/getting-started/go/#delete_the_database).

### 4. Database-Specific Issues

The schema, report and bad-data files [generated by
HarbourBridge](#files-generated-by-harbourbridge) contain detailed information
about the schema and data conversion process, including issues and problems
encountered.

### 5. Reporting Issues

 If you are having problems with HarbourBridge, please [submit an
 issue](https://github.com/cloudspannerecosystem/harbourbridge/issues).
